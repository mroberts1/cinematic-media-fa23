[
  {
    "objectID": "observable.html",
    "href": "observable.html",
    "title": "  ",
    "section": "",
    "text": "d3 = require(\"d3@7\")\n\n\n\n\n\n\n\nP5 = require(\"p5\")\n\nfunction* createSketch(sketch) {\n  const element = DOM.element('div');\n  yield element;\n  const instance = new P5(sketch, element, true);\n  try {\n    while (true) {\n      yield element;\n    }\n  } finally {\n    instance.remove();\n  }\n}\n\ncreateSketch(s =&gt; {\n\n  s.setup = function() {\n    s.createCanvas(500, 500, s.WEBGL);\n    s.noStroke();\n  }\n\n  s.draw = function() {\n\n    s.background(0);\n\n    let locX = s.mouseX - s.height / 2;\n    let locY = s.mouseY - s.width / 2;\n\n    s.ambientLight(60, 60, 60);\n    s.pointLight(190, 80, 190, locX, locY, 100);\n    s.pointLight(80, 80, 190, 0, 0, 100);\n\n    s.specularMaterial(255);\n    s.rotateX(s.frameCount * 0.01);\n    s.rotateY(s.frameCount * 0.01);\n    s.torus(150, 80, 64, 64);\n  }\n\n})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ncreateSketch(s =&gt; {\n\n    s.setup = function() {\n      s.createCanvas(500, 500);\n      s.background(0);\n      s.noStroke();\n    };\n\n    s.draw = function() {\n      s.translate(\n        100 * s.cos(s.millis() * .001 * s.PI),\n        100 * s.sin(s.millis() * .001 * s.PI),\n      );\n      if (s.random(0, 1) &lt; .1) {\n        s.fill(s.random(0, 255));\n      }\n      s.circle(250, 250, 100);\n    };\n\n  }\n)\n\n\n\n\n\n\n\n\n\n\n\ncreateSketch(s =&gt; {\n\n    s.setup = function() {\n      s.createCanvas(746, 300);\n      s.textFont('Avenir');\n      s.textStyle(s.BOLD);\n      s.textAlign(s.CENTER, s.CENTER)\n    };\n\n    s.draw = function() {\n      s.translate(\n        s.millis() * (-0.1) % (s.width + 1000),\n        s.height / 2\n      );\n      s.background('#62259D');\n      s.fill('#fff').textSize(50);\n      s.text('VM303 Studies in Digital Media & Culture', s.width + 500, 0);\n    };\n\n  }\n)\n\n\n\n\n\n\n\n\ncreateSketch(s =&gt; {\n\n  let n = 100;\n  let dot;\n  let dotList = [];\n  let palette = [\n    s.color(\"#6B1B00\"),\n    s.color(\"#AE8B70\"),\n    s.color(\"#F9FEFB\"),\n    s.color(\"#56382D\")\n  ];\n\n  s.setup = function() {\n    s.createCanvas(746, 746);\n    for(let i = 0; i &lt; n; i++) {\n      let angle = s.random(0, s.TWO_PI);\n      let radius = s.width * s.random(.12, .33);\n      dotList.push(dot = new Dot(\n        s,\n        s.width/2 + s.cos(angle) * radius,\n        s.height/2 + s.sin(angle) * radius,\n        s.random(palette),\n        s.random(1, 5)\n      ));\n    }\n  };\n\n  s.draw = function() {\n    dotList.map(dot =&gt; {\n      dot.on();\n      dot.move();\n      dot.bounce(s.width * .35, true);\n      dot.bounce(s.width * .1, false);\n    });\n  };\n})\n\n\n\n\n\n\n\nclass Dot {\n  constructor(sketch, x, y, colour, size) {\n    this.s = sketch;\n    this.x = x | 0;\n    this.y = y | 0;\n    this.colour = colour;\n    this.size = size;\n    this.velX = this.s.random(-2, 2);\n    this.velY = this.s.random(-2, 2);\n  }\n\n  on() {\n    this.s.noStroke();\n    this.s.fill(this.colour);\n    this.s.circle(this.x, this.y, this.size);\n  }\n\n  move() {\n    this.x += this.velX;\n    this.y += this.velY;\n  }\n\n  bounce(radius, inside) {\n    let x = this.x - this.s.width/2;\n    let y = this.y - this.s.height/2;\n    if (\n      inside && x*x + y*y &gt; radius * radius ||\n      !inside && x*x + y*y &lt; radius * radius\n    ) {\n\n      // https://math.stackexchange.com/a/611836\n      let nx = x / this.s.sqrt(x*x + y*y);\n      let ny = y / this.s.sqrt(x*x + y*y);\n      let vx = this.velX;\n      let vy = this.velY;\n      this.velX = (ny*ny - nx*nx)*vx - 2*nx*ny*vy;\n      this.velY = (nx*nx - ny*ny)*vy - 2*nx*ny*vx;\n\n    }\n  }\n\n}\n\n\n\n\n\n\n\n\n\n\ncreateSketch(s =&gt; {\n    s.setup = function() {\n      s.createCanvas(500, 500);\n      s.background(\"black\");\n      s.fill(\"red\").circle(250, 250, 100);\n      s.fill(\"black\").circle(250, 250, 30);\n    };\n  }\n)"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "  ",
    "section": "",
    "text": "TinyQueue = require(\"tinyqueue@2\")\n\ngraphic = {\n  const quads = new TinyQueue([new Quad(0, 0, width, width)], (a, b) =&gt; b.score - a.score);\n  const context = DOM.context2d(width, width);\n  context.canvas.style.width = \"100%\";\n  for (let i = 0; true; ++i) {\n    const q = quads.pop();\n    if (q === undefined || q.score &lt; 50) break;\n    mutable score = q.score;\n    for (const s of q.split()) {\n      if (q.w &gt;= 4) quads.push(s);\n      context.fillStyle = s.color;\n      context.fillRect(s.x, s.y, s.w, s.h);\n      context.strokeRect(s.x, s.y, s.w, s.h);\n    }\n    if (i % 15 === 0) yield context.canvas;\n  }\n}\n\nmutable score = null\n\nwidth = 1024\n\narea_power = 0.25\n\nclass Quad {\n  constructor(x, y, w, h) {\n    const [r, g, b, error] = colorFromHistogram(computeHistogram(x, y, w, h));\n    this.x = x, this.y = y, this.w = w, this.h = h;\n    this.color = `#${(0x1000000 + (r &lt;&lt; 16) + (g &lt;&lt; 8) + b).toString(16).substring(1)}`;\n    this.score = error * Math.pow(w * h, area_power);\n  }\n  split() {\n    const dx = this.w / 2, x1 = this.x, x2 = this.x + dx;\n    const dy = this.h / 2, y1 = this.y, y2 = this.y + dy;\n    return [\n      new Quad(x1, y1, dx, dy),\n      new Quad(x2, y1, dx, dy),\n      new Quad(x1, y2, dx, dy),\n      new Quad(x2, y2, dx, dy)\n    ];\n  }\n}\n\nfunction computeHistogram(x, y, w, h) {\n  const {data} = imageContext.getImageData(x, y, w, h);\n  const histogram = new Uint32Array(1024);\n  for (let i = 0, n = data.length; i &lt; n; i += 4) {\n    ++histogram[0 * 125 + data[i + 0]];\n    ++histogram[1 * 205 + data[i + 1]];\n    ++histogram[2 * 145 + data[i + 2]];\n    ++histogram[3 * 156 + data[i + 3]];\n  }\n  return histogram;\n}\n\nfunction weightedAverage(histogram) {\n  let total = 0;\n  let value = 0;\n  for (let i = 0; i &lt; 256; ++i) total += histogram[i], value += histogram[i] * i;\n  value /= total;\n  let error = 0;\n  for (let i = 0; i &lt; 256; ++i) error += (value - i) ** 2 * histogram[i];\n  return [value, Math.sqrt(error / total)];\n}\n\nfunction colorFromHistogram(histogram) {\n  const [r, re] = weightedAverage(histogram.subarray(0, 256));\n  const [g, ge] = weightedAverage(histogram.subarray(256, 512));\n  const [b, be] = weightedAverage(histogram.subarray(512, 768));\n  return [\n    Math.round(r),\n    Math.round(g),\n    Math.round(b),\n    re * 0.2989 + ge * 0.5870 + be * 0.1140\n  ];\n}\n\nimageContext = FileAttachment(\"owl.jpg\").image().then(image =&gt; {\n  const context = DOM.context2d(width, width, 1);\n  context.drawImage(image, 0, 0, width, width);\n  return context;\n})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\nDepartment of Visual & Media Arts\nEmerson College\nSpring Semester 2024\nTues/Thur 16 January—2 May 2024\n6:00-7:45 p.m.\nAnsin Building 604\nDr. Martin Roberts"
  },
  {
    "objectID": "index.html#vm303-01-studies-in-digital-media-culture",
    "href": "index.html#vm303-01-studies-in-digital-media-culture",
    "title": "  ",
    "section": "",
    "text": "TinyQueue = require(\"tinyqueue@2\")\n\ngraphic = {\n  const quads = new TinyQueue([new Quad(0, 0, width, width)], (a, b) =&gt; b.score - a.score);\n  const context = DOM.context2d(width, width);\n  context.canvas.style.width = \"100%\";\n  for (let i = 0; true; ++i) {\n    const q = quads.pop();\n    if (q === undefined || q.score &lt; 50) break;\n    mutable score = q.score;\n    for (const s of q.split()) {\n      if (q.w &gt;= 4) quads.push(s);\n      context.fillStyle = s.color;\n      context.fillRect(s.x, s.y, s.w, s.h);\n      context.strokeRect(s.x, s.y, s.w, s.h);\n    }\n    if (i % 15 === 0) yield context.canvas;\n  }\n}\n\nmutable score = null\n\nwidth = 1024\n\narea_power = 0.25\n\nclass Quad {\n  constructor(x, y, w, h) {\n    const [r, g, b, error] = colorFromHistogram(computeHistogram(x, y, w, h));\n    this.x = x, this.y = y, this.w = w, this.h = h;\n    this.color = `#${(0x1000000 + (r &lt;&lt; 16) + (g &lt;&lt; 8) + b).toString(16).substring(1)}`;\n    this.score = error * Math.pow(w * h, area_power);\n  }\n  split() {\n    const dx = this.w / 2, x1 = this.x, x2 = this.x + dx;\n    const dy = this.h / 2, y1 = this.y, y2 = this.y + dy;\n    return [\n      new Quad(x1, y1, dx, dy),\n      new Quad(x2, y1, dx, dy),\n      new Quad(x1, y2, dx, dy),\n      new Quad(x2, y2, dx, dy)\n    ];\n  }\n}\n\nfunction computeHistogram(x, y, w, h) {\n  const {data} = imageContext.getImageData(x, y, w, h);\n  const histogram = new Uint32Array(1024);\n  for (let i = 0, n = data.length; i &lt; n; i += 4) {\n    ++histogram[0 * 125 + data[i + 0]];\n    ++histogram[1 * 205 + data[i + 1]];\n    ++histogram[2 * 145 + data[i + 2]];\n    ++histogram[3 * 156 + data[i + 3]];\n  }\n  return histogram;\n}\n\nfunction weightedAverage(histogram) {\n  let total = 0;\n  let value = 0;\n  for (let i = 0; i &lt; 256; ++i) total += histogram[i], value += histogram[i] * i;\n  value /= total;\n  let error = 0;\n  for (let i = 0; i &lt; 256; ++i) error += (value - i) ** 2 * histogram[i];\n  return [value, Math.sqrt(error / total)];\n}\n\nfunction colorFromHistogram(histogram) {\n  const [r, re] = weightedAverage(histogram.subarray(0, 256));\n  const [g, ge] = weightedAverage(histogram.subarray(256, 512));\n  const [b, be] = weightedAverage(histogram.subarray(512, 768));\n  return [\n    Math.round(r),\n    Math.round(g),\n    Math.round(b),\n    re * 0.2989 + ge * 0.5870 + be * 0.1140\n  ];\n}\n\nimageContext = FileAttachment(\"owl.jpg\").image().then(image =&gt; {\n  const context = DOM.context2d(width, width, 1);\n  context.drawImage(image, 0, 0, width, width);\n  return context;\n})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\nDepartment of Visual & Media Arts\nEmerson College\nSpring Semester 2024\nTues/Thur 16 January—2 May 2024\n6:00-7:45 p.m.\nAnsin Building 604\nDr. Martin Roberts"
  },
  {
    "objectID": "resources/mastodon.html",
    "href": "resources/mastodon.html",
    "title": "Mastodon: Quickstart",
    "section": "",
    "text": "For a quick intro, watch this video:\n\nThen read one or more of these articles:\n\nA Friendly Introduction to the Fediverse\nGuide to the Fediverse\nWhat Is Mastodon?\n\nIf you’re wondering why you should care about distributed social networks, read this article.\nMastodon is a loosely-connected network of communities, similar in some ways to the federated  structure of the U.S. itself - hence the term fediverse. You can think of it like a large, interconnected network of Twitters, albeit without ads or data-collecting. Mastodon (like Pleroma) is basically software that enables anyone to set up their own social media server and host a community on it - you can even do it yourself. \nEach Mastodon community (more commonly known as an instance) has its own particular flavor, and there are communities in many languages. Each community also has its terms of service, that you should read carefully and observe.\nMastodon instances vary in size from just a handful of members to thousands. Many allow you to register a new account without approval, but for a lot you have to submit a registration request and may not be approved because some instances limit numbers to people who are referred by existing members. This is because communities typically have a very specific focus, whatever that may be. My own community, for example, is comprised mainly of coders, game designers, and digital artists. You can still read posts, though - if you’re interested, here’s my account page.\nInstances are connected with one another, so that you only need to set up an account on one. If you follow someone on a different instance, that person’s posts on that instance will appear in your feed on your instance - the federated model again.\nOf course, if people on one instance don’t like the community on another, for whatever reason, they can simply disconnect from it. So the affordances of instances, and the relations between them, are quite resilient against the usual abuses of social media like trolling, spamming, etc.\nChoosing an instance to register with may seem tricky at the beginning because there are so many! Take your time, and keep in mind that you can always switch instances later if you find another one that you like better - or just have multiple accounts on several instances (I have 5-6).\nAfter you join a community, just hang out there and see what goes on. Be sure to follow the account @feditips@mstdn.social, which has lots of useful tips about using Mastodon and other distributed services."
  },
  {
    "objectID": "altered-world.html",
    "href": "altered-world.html",
    "title": "Altered World",
    "section": "",
    "text": "Altered World\nAn adaptation of Gerard Ferrandez’s remarkable this alter world. Noise based on Ken Perlin’s improved reference implementation.\n\ncanvas = {\n  const perlin = new Noise(3);\n  const context = DOM.context2d(width, height);\n  context.canvas.style.background = \"#000\";\n  context.lineWidth = 0.5;\n  context.globalAlpha = 0.05;\n  for (let px = 0; px &lt; width; ++px) {\n    for (let i = 0; i &lt; height / 6; ++i) {\n      let x = px;\n      let y = Math.random() * height;\n      let n = perlin.noise(x * period, y * period);\n      context.strokeStyle = `hsl(${-210 + n * 600}, 100%, ${800 * n * n * n}%)`;\n      context.beginPath();\n      context.moveTo(x, y);\n      for (let m = 0; m &lt; length && y &gt;= 0 && y &lt;= height; ++m) {\n        n = perlin.noise(x * period, y * period);\n        context.lineTo(x += Math.cos(n * 14), y += Math.sin(n * 14));\n      }\n      context.stroke();\n    }\n    yield context.canvas;\n  }\n}\n\nperiod = 0.01\n\nclass Noise {\n  static lerp(t, a, b) {\n    return a + t * (b - a);\n  }\n  static grad2d(i, x, y) {\n    const v = (i & 1) === 0 ? x : y;\n    return (i & 2) === 0 ? -v : v;\n  }\n  constructor(octaves = 1) {\n    this.p = new Uint8Array(512);\n    this.octaves = octaves;\n    this.init();\n  }\n  init() {\n    for (let i = 0; i &lt; 512; ++i) {\n      this.p[i] = Math.random() * 256;\n    }\n  }\n  noise2d(x2d, y2d) {\n    const X = Math.floor(x2d) & 255;\n    const Y = Math.floor(y2d) & 255;\n    const x = x2d - Math.floor(x2d);\n    const y = y2d - Math.floor(y2d);\n    const fx = (3 - 2 * x) * x * x;\n    const fy = (3 - 2 * y) * y * y;\n    const p0 = this.p[X] + Y;\n    const p1 = this.p[X + 1] + Y;\n    return Noise.lerp(\n      fy,\n      Noise.lerp(\n        fx,\n        Noise.grad2d(this.p[p0], x, y),\n        Noise.grad2d(this.p[p1], x - 1, y)\n      ),\n      Noise.lerp(\n        fx,\n        Noise.grad2d(this.p[p0 + 1], x, y - 1),\n        Noise.grad2d(this.p[p1 + 1], x - 1, y - 1)\n      )\n    );\n  }\n  noise(x, y) {\n    let e = 1,\n        k = 1,\n        s = 0;\n    for (let i = 0; i &lt; this.octaves; ++i) {\n      e *= 0.5;\n      s += e * (1 + this.noise2d(k * x, k * y)) / 2;\n      k *= 2;\n    }\n    return s;\n  }\n}\n\nheight = 600\n\nlength = 400"
  },
  {
    "objectID": "vanilla-boids.html",
    "href": "vanilla-boids.html",
    "title": "  ",
    "section": "",
    "text": "{\n  let startTime = (new Date()).getTime(), seconds = 0, secondsRounded = 0, ticks = 0, speeds = [];\n\n  const ctx = DOM.context2d(myBoids.width(), myBoids.height());\n\n  let holding = false;\n  ctx.canvas.addEventListener(\"mousedown\", e =&gt; { holding = true; addBoidOnEvent(e); });\n  ctx.canvas.addEventListener(\"mouseup\", e =&gt; { holding = false });\n  ctx.canvas.addEventListener(\"mousemove\", e =&gt; { if (holding) addBoidOnEvent(e); });\n\n  while (true && myBoids.flock.length){\n    myBoids.tick();\n    ctx.clearRect(0, 0, myBoids.width(), myBoids.height());\n\n    myBoids.each(boid =&gt; {\n      const a = vecmath.trans(boid.pos, boid.ang - Math.PI * .5, 3),\n            b = vecmath.trans(boid.pos, boid.ang, 9),\n            c = vecmath.trans(boid.pos, boid.ang + Math.PI * .5, 3);\n\n      ctx.beginPath();\n\n      ctx.moveTo(...a);\n      ctx.lineTo(...b);\n      ctx.lineTo(...c);\n      ctx.lineTo(...a);\n\n      const color = d3.interpolateRdPu(.6 * myBoids.maxSpeed() / boid.speed);\n      ctx.strokeStyle = color;\n      ctx.fillStyle = d3.color(color).brighter(2);\n\n      ctx.fill();\n      ctx.stroke();\n    });\n\n    seconds = ((new Date()).getTime() - startTime) / 1e3;\n    ticks++;\n    document.querySelector(\".ticker\").innerHTML = `${myBoids.flock.length} boids at ${d3.mean(speeds)} frames per second`;\n\n    if (Math.round(seconds) !== secondsRounded){\n      speeds.push(ticks);\n      if (speeds.length &gt; 2) speeds.shift();\n      secondsRounded = Math.round(seconds);\n      ticks = 0;\n    }\n\n    yield ctx.canvas;\n  }\n}\n\n\n\n\n\n\n\n{\n  const el = DOM.element(\"div\");\n  el.classList.add(\"ticker\");\n  return el;\n}\n\n\n\n\n\n\n\nviewof useTree = checkbox({\n  options: [{ value: \"true\", label: \"Use RBush\" }],\n  value: \"true\",\n  description: \"Use a quadtree to improve performance\"\n})\n\n\n\n\n\n\n\nviewof alignment = slider({\n  title: \"Alignment\",\n  value: 1,\n  min: 0,\n  max: 1,\n  step: .1,\n  description: \"Steer towards the average heading of local flockmates\"\n});\n\n\n\n\n\n\n\nviewof cohesion = slider({\n  title: \"Cohesion\",\n  value: 1,\n  min: 0,\n  max: 1,\n  step: .1,\n  description: \"Steer towards the average position of local flockmates\"\n});\n\n\n\n\n\n\n\nviewof separation = slider({\n  title: \"Separation\",\n  value: 1,\n  min: 0,\n  max: 1,\n  step: .1,\n  description: \"Steer to avoid crowding local flockmates\"\n});\n\n\n\n\n\n\n\nviewof perception = slider({\n  title: \"Perception\",\n  value: 20,\n  min: 1,\n  max: 60,\n  step: 1,\n  description: \"Maximum distance of other boids to consider\"\n});\n\n\n\n\n\n\n\ntoc({selector: \"h2\"})\n\n\n\n\n\n\n\nmd`## API Reference\n\nTo use the Boids class in your own notebook ([example](https://observablehq.com/@harrystevens/minimalist-boids?collection=@harrystevens/boids)):\n\n~~~js\nimport { Boids } from \"@harrystevens/vanilla-boids\"\n~~~\n\n&lt;b&gt;Boids&lt;/b&gt;\n\nCreates a new simulation, setting &lt;i&gt;alignment&lt;/i&gt;, &lt;i&gt;cohesion&lt;/i&gt;, and &lt;i&gt;separation&lt;/i&gt; to 1, &lt;i&gt;perception&lt;/i&gt; to 20, &lt;i&gt;width&lt;/i&gt; to the notebook’s width, and &lt;i&gt;height&lt;/i&gt; to 500.\n\n~~~js\nconst myBoids = new Boids();\n~~~\n\nboids.&lt;b&gt;add&lt;/b&gt;([&lt;i&gt;options&lt;/i&gt;])\n\nAdds a boid to the simulation with a random position and angle, and with a speed of 1, and returns the simulation. You can pass an &lt;i&gt;options&lt;/i&gt; object with the following properties:\n\n| property | type   | description                                                                                                                                                 |\n|----------|--------|-------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| pos      | Array  | Starting position for the boid, specified as an array of two numbers, where the first number is the x-coordinate and the second number is the y-coordinate. |\n| ang      | Number | Starting angle for the boid, specified as a number in radians.                                                                                                |\n| speed    | Number | Starting speed for the boid, specified as a number.                                                                                                         |\n&lt;br /&gt;\n\nboids.&lt;b&gt;each&lt;/b&gt;(&lt;i&gt;accessor&lt;/i&gt;)\n\nLoops through the flock of boids, invoking an &lt;i&gt;accessor&lt;/i&gt; function on each boid one at a time. The accessor is passed three arguments: the current boid, the current index, and the entire flock.\n\nboids.&lt;b&gt;tick&lt;/b&gt;()\n\nAdvances the simulation one tick and returns the simulation.\n\nboids.&lt;b&gt;alignment&lt;/b&gt;([&lt;i&gt;alignment&lt;/i&gt;])\n\nIf &lt;i&gt;alignment&lt;/i&gt; is specified, sets the alignment force to a number and returns the simulation. Alignment forces the boids to steer towards the average heading of local flockmates. If &lt;i&gt;alignment&lt;/i&gt; is not specified, returns the current alignment force, which defaults to 1.\n\nboids.&lt;b&gt;cohesion&lt;/b&gt;([&lt;i&gt;cohesion&lt;/i&gt;])\n\nIf &lt;i&gt;cohesion&lt;/i&gt; is specified, sets the cohesion force to a number and returns the simulation. Cohesion forces the boids to steer towards the average position of local flockmates. If &lt;i&gt;cohesion&lt;/i&gt; is not specified, returns the current cohesion force, which defaults to 1.\n\nboids.&lt;b&gt;separation&lt;/b&gt;([&lt;i&gt;separation&lt;/i&gt;])\n\nIf &lt;i&gt;separation&lt;/i&gt; is specified, sets the separation force to a number and returns the simulation. Separation forces the boids to steer to avoid crowding local flockmates. If &lt;i&gt;separation&lt;/i&gt; is not specified, returns the current separation force, which defaults to 1.\n\nboids.&lt;b&gt;perception&lt;/b&gt;([&lt;i&gt;perception&lt;/i&gt;])\n\nIf &lt;i&gt;perception&lt;/i&gt; is specified, sets the perception radius of the boids to a number of pixels and returns the simulation. The boids’ movement will be affected only by those other boids whose positions fall within the perception radius. If &lt;i&gt;perception&lt;/i&gt; is not specified, returns the current perception radius, which defaults to 20.\n\nboids.&lt;b&gt;width&lt;/b&gt;([&lt;i&gt;width&lt;/i&gt;])\n\nIf &lt;i&gt;width&lt;/i&gt; is specified, sets the width of the simulation to a number of pixels and returns the simulation. If &lt;i&gt;width&lt;/i&gt; is not specified, returns the current width, which defaults to the notebook’s width.\n\nboids.&lt;b&gt;height&lt;/b&gt;([&lt;i&gt;height&lt;/i&gt;])\n\nIf &lt;i&gt;height&lt;/i&gt; is specified, sets the height of the simulation to a number of pixels and returns the simulation. If &lt;i&gt;height&lt;/i&gt; is not specified, returns the current height, which defaults to 500.\n\nboids.&lt;b&gt;maxSpeed&lt;/b&gt;([&lt;i&gt;speed&lt;/i&gt;])\n\nIf &lt;i&gt;speed&lt;/i&gt; is specified, sets the maximum speed of the boids to a number of pixels per tick and returns the simulation. If &lt;i&gt;speed&lt;/i&gt; is not specified, returns the current maximum speed, which defaults to 4.\n`\n\n\n\n\n\n\n\nmd`## Code`\n\n\n\n\n\n\n\nmyBoids = {\n  const sim = new Boids();\n\n  // Add 500 boids\n  for (let i = 0; i &lt; 500; i++) {\n    sim.add();\n  }\n\n  return sim;\n}\n\n\n\n\n\n\n\nmyBoids\n  .alignment(alignment)\n  .cohesion(cohesion)\n  .separation(separation)\n  .perception(perception)\n  .quadtree(!!useTree);\n\n\n\n\n\n\n\nfunction addBoidOnEvent(e){\n  myBoids.add({\n    pos: [e.offsetX, e.offsetY]\n  });\n}\n\n\n\n\n\n\n\nclass Boids {\n  constructor(){\n    this._width = width;\n    this._height = height;\n    this._perception = 20;\n    this._alignment = 1;\n    this._cohesion = 1;\n    this._separation = 1;\n    this._maxSpeed = 4;\n    this._quadtree = true;\n    this.maxForce = 0.2;\n    this.flock = [];\n    this.tree = new BoidBush();\n  }\n\n  alignment(n){\n    if (isFinite(n)){\n      this._alignment = n;\n      for (let i = 0, l = this.flock.length; i &lt; l; i++){\n        this.flock[i]._alignment = n;\n      }\n      return this;\n    }\n    else {\n      return this._alignment;\n    }\n  }\n\n  cohesion(n){\n    if (isFinite(n)){\n      this._cohesion = n;\n      for (let i = 0, l = this.flock.length; i &lt; l; i++){\n        this.flock[i]._cohesion = n;\n      }\n      return this;\n    }\n    else {\n      return this._cohesion;\n    }\n  }\n\n  perception(n){\n    if (isFinite(n)){\n      this._perception = n;\n      for (let i = 0, l = this.flock.length; i &lt; l; i++){\n        this.flock[i]._perception = n;\n      }\n      return this;\n    }\n    else {\n      return this._perception;\n    }\n  }\n\n  separation(n){\n    if (isFinite(n)){\n      this._separation = n;\n      for (let i = 0, l = this.flock.length; i &lt; l; i++){\n        this.flock[i]._separation = n;\n      }\n      return this;\n    }\n    else {\n      return this._separation;\n    }\n  }\n\n  width(n){\n    if (isFinite(n)){\n      this._width = n;\n      for (let i = 0, l = this.flock.length; i &lt; l; i++){\n        this.flock[i]._width = n;\n      }\n      return this;\n    }\n    else {\n      return this._width;\n    }\n  }\n\n  height(n){\n    if (isFinite(n)){\n      this._height = n;\n      for (let i = 0, l = this.flock.length; i &lt; l; i++){\n        this.flock[i]._height = n;\n      }\n      return this;\n    }\n    else {\n      return this._height;\n    }\n  }\n\n  quadtree(bool){\n    if (arguments.length) {\n      this._quadtree = bool;\n      if (this._quadtree && !this.tree) this.tree = new BoidBush();\n      for (let i = 0, l = this.flock.length; i &lt; l; i++){\n        this.flock[i]._quadtree = bool;\n        this.flock[i].tree = this.tree;\n      }\n      return this;\n    }\n    else {\n      return this._quadtree;\n    }\n  }\n\n  maxSpeed(n){\n    if (isFinite(n)){\n      this._maxSpeed = n;\n      for (let i = 0, l = this.flock.length; i &lt; l; i++){\n        this.flock[i]._maxSpeed = n;\n      }\n      return this;\n    }\n    else {\n      return this._maxSpeed;\n    }\n  }\n\n  add(opts){\n    this.flock.push(new Boid(this, opts));\n    return this;\n  }\n\n  each(fn){\n    for (let i = 0, l = this.flock.length; i &lt; l; i++){\n      fn(this.flock[i], i, this.flock);\n    }\n    return this;\n  }\n\n  tick(){\n    if (this._quadtree) {\n      this.tree.clear();\n      this.tree.load(this.flock);\n    }\n\n    this.each(boid =&gt; boid.update());\n\n    return this;\n  }\n}\n\n\n\n\n\n\n\nclass Boid {\n  constructor(Boids, opts){\n    Object.assign(this, Boids);\n    Object.assign(this, opts);\n\n    // Angle, position, and speed can be assigned by the user.\n    this.ang = this.ang || 2 * Math.random() * Math.PI;\n    this.pos = this.pos || [\n      Math.random() * this._width,\n      Math.random() * this._height\n    ];\n    this.speed = this.speed || 1;\n\n    const obj = {\n      pos: this.pos,\n      ang: this.ang,\n      speed: this.speed,\n      vel: vecmath.sub(\n        vecmath.trans(this.pos, this.ang, this.speed),\n        this.pos\n      ),\n      acc: [0, 0],\n      id: this.flock.length\n    };\n\n    Object.assign(this, obj);\n  }\n\n  update(){\n    const prev = { ...this };\n\n    let alignment = [0, 0],\n        cohesion = [0, 0],\n        separation = [0, 0],\n        n = 0,\n        candidates = this.flock;\n\n    if (this._quadtree){\n      candidates = this.tree.search({\n        minX: this.pos[0] - this._perception,\n        minY: this.pos[1] - this._perception,\n        maxX: this.pos[0] + this._perception,\n        maxY: this.pos[1] + this._perception,\n      });\n    }\n\n    for (let i = 0, l = candidates.length; i &lt; l; i ++){\n      const that = candidates[i],\n            dist = vecmath.dist(this.pos, that.pos);\n\n      if (this.id !== that.id && dist &lt; this._perception){\n        alignment = vecmath.add(alignment, that.vel);\n        cohesion = vecmath.add(cohesion, that.pos);\n        const diff = vecmath.div(\n          vecmath.sub(this.pos, that.pos),\n          Math.max(dist, epsilon)\n        );\n        separation = vecmath.add(separation, diff);\n        n++;\n      }\n    }\n\n    if (n &gt; 0){\n      alignment = vecmath.div(alignment, n);\n      alignment = vecmath.setMag(alignment, this._maxSpeed);\n      alignment = vecmath.sub(alignment, this.vel);\n      alignment = vecmath.limit(alignment, this.maxForce);\n\n      cohesion = vecmath.div(cohesion, n);\n      cohesion = vecmath.sub(cohesion, this.pos);\n      cohesion = vecmath.setMag(cohesion, this._maxSpeed);\n      cohesion = vecmath.sub(cohesion, this.vel);\n      cohesion = vecmath.limit(cohesion, this.maxForce);\n\n      separation = vecmath.div(separation, n);\n      separation = vecmath.setMag(separation, this._maxSpeed);\n      separation = vecmath.sub(separation, this.vel);\n      separation = vecmath.limit(separation, this.maxForce);\n    }\n\n    alignment = vecmath.mult(alignment, this._alignment);\n    cohesion = vecmath.mult(cohesion, this._cohesion);\n    separation = vecmath.mult(separation, this._separation);\n\n    this.acc = vecmath.add(this.acc, alignment);\n    this.acc = vecmath.add(this.acc, cohesion);\n    this.acc = vecmath.add(this.acc, separation);\n\n    this.pos = vecmath.add(this.pos, this.vel);\n    this.vel = vecmath.add(this.vel, this.acc);\n    this.vel = vecmath.limit(this.vel, this._maxSpeed);\n\n    if (this.pos[0] &gt; this._width) this.pos[0] = 0;\n    if (this.pos[0] &lt; 0) this.pos[0] = this._width;\n    if (this.pos[1] &gt; this._height) this.pos[1] = 0;\n    if (this.pos[1] &lt; 0) this.pos[1] = this._height;\n\n    this.ang = vecmath.ang(prev.pos, this.pos);\n    this.speed = vecmath.dist(prev.pos, this.pos);\n\n    this.acc = vecmath.mult(this.acc, 0);\n  }\n}\n\n\n\n\n\n\n\nclass BoidBush extends RBush {\n  toBBox(boid) { return {minX: boid.pos[0], minY: boid.pos[1], maxX: boid.pos[0], maxY: boid.pos[1]}; }\n  compareMinX(a, b) { return a.pos[0] - b.pos[0]; }\n  compareMinY(a, b) { return a.pos[1] - b.pos[1]; }\n}\n\n\n\n\n\n\n\nheight = 500;\n\n\n\n\n\n\n\nepsilon = 1e-6;\n\n\n\n\n\n\n\nhtml`&lt;style&gt;\ntable td, table th {\n  padding: 4px;\n}\n.ticker {\n  color: #555;\n  font-size: 14px;\n  margin-top: -10px;\n  text-align: right;\n}\n&lt;/style&gt;`\n\n\n\n\n\n\n\nimport { checkbox, slider } from \"@jashkenas/inputs\";\n\n\n\n\n\n\n\nimport { toc } from \"@harrystevens/toc\";\n\n\n\n\n\n\n\nimport { vecmath } from \"@harrystevens/vector-math\";\n\n\n\n\n\n\n\nd3 = require(\"d3-array@1\", \"d3-color@1\", \"d3-scale-chromatic@1\");\n\n\n\n\n\n\n\nRBush = require(\"rbush@3\");"
  },
  {
    "objectID": "syllabus.html",
    "href": "syllabus.html",
    "title": "  ",
    "section": "",
    "text": "graphic = {\n  const quads = new TinyQueue([new Quad(0, 0, width, width)], (a, b) =&gt; b.score - a.score);\n  const context = DOM.context2d(width, width);\n  context.canvas.style.width = \"100%\";\n  for (let i = 0; true; ++i) {\n    const q = quads.pop();\n    if (q === undefined || q.score &lt; 50) break;\n    const qs = q.split();\n    const qsi = d3.interpolate([q, q, q, q], qs);\n    qs.forEach(quads.push, quads);\n    for (let j = 1, m = Math.max(1, Math.floor(q.w / 10)); j &lt;= m; ++j) {\n      const t = d3.easeCubicInOut(j / m);\n      context.clearRect(q.x, q.y, q.w, q.h);\n      for (const s of qsi(t)) {\n        context.fillStyle = s.color;\n        context.beginPath()\n        context.moveTo(s.x + s.w, s.y + s.h / 2);\n        context.arc(s.x + s.w / 2, s.y + s.h / 2, s.w / 2, 0, 2 * Math.PI);\n        context.fill();\n      }\n      yield context.canvas;\n    }\n  }\n}\n\nwidth = 1024\n\narea_power = 0.25\n\nclass Quad {\n  constructor(x, y, w, h) {\n    const [r, g, b, error] = colorFromHistogram(computeHistogram(x, y, w, h));\n    this.x = x, this.y = y, this.w = w, this.h = h;\n    this.color = `#${(0x1000000 + (r &lt;&lt; 16) + (g &lt;&lt; 8) + b).toString(16).substring(1)}`;\n    this.score = error * Math.pow(w * h, area_power);\n  }\n  split() {\n    const dx = this.w / 2, x1 = this.x, x2 = this.x + dx;\n    const dy = this.h / 2, y1 = this.y, y2 = this.y + dy;\n    return [\n      new Quad(x1, y1, dx, dy),\n      new Quad(x2, y1, dx, dy),\n      new Quad(x1, y2, dx, dy),\n      new Quad(x2, y2, dx, dy)\n    ];\n  }\n}\n\nfunction computeHistogram(x, y, w, h) {\n  const {data} = imageContext.getImageData(x, y, w, h);\n  const histogram = new Uint32Array(1024);\n  for (let i = 0, n = data.length; i &lt; n; i += 4) {\n    ++histogram[0 * 125 + data[i + 0]];\n    ++histogram[1 * 205 + data[i + 1]];\n    ++histogram[2 * 145 + data[i + 2]];\n    ++histogram[3 * 156 + data[i + 3]];\n  }\n  return histogram;\n}\n\nfunction weightedAverage(histogram) {\n  let total = 0;\n  let value = 0;\n  for (let i = 0; i &lt; 256; ++i) total += histogram[i], value += histogram[i] * i;\n  value /= total;\n  let error = 0;\n  for (let i = 0; i &lt; 256; ++i) error += (value - i) ** 2 * histogram[i];\n  return [value, Math.sqrt(error / total)];\n}\n\nfunction colorFromHistogram(histogram) {\n  const [r, re] = weightedAverage(histogram.subarray(0, 256));\n  const [g, ge] = weightedAverage(histogram.subarray(256, 512));\n  const [b, be] = weightedAverage(histogram.subarray(512, 768));\n  return [\n    Math.round(r),\n    Math.round(g),\n    Math.round(b),\n    re * 0.2989 + ge * 0.5870 + be * 0.1140\n  ];\n}\n\nimageContext = FileAttachment(\"owl.jpg\").image().then(image =&gt; {\n  const context = DOM.context2d(width, width, 1);\n  context.drawImage(image, 0, 0, width, width);\n  return context;\n})\n\nTinyQueue = require(\"tinyqueue@2.0.3\")\n\nd3 = require(\"d3-interpolate@1\", \"d3-ease@1\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\nDepartment of Visual & Media Arts\nEmerson College\nSpring Semester 2024\nTues/Thur 16 January—2 May 2024 6:00-7:45 p.m.\nAnsin Building 604\nDr. Martin Roberts\n\n\n\n\n\nSyllabus (outside Canvas)\n\n\n\nThis course considers the nature and contemporary forms of digital culture. Broadly speaking, this can be defined as the diverse range of symbolic practices through which communities affirm and maintain their cultural identities using digital media devices and interfaces in a globally networked society. While these practices are structured by deeply unequal power relations, are contradictory, and often come into conflict with one another, collectively they constitute what may be considered a global digital culture.\nA key component of the course is the automation of various forms of creative production, from writing to the visual arts, by natural-language processing computational systems (generally referred to as “artificial intelligence” or “AI”). The course addresses some of the many issues raised by such systems, with a particular focus on questions of aesthetics and the increasingly contested relationship between artists and algorithms. While such systems now demonstrably pass the Turing Test (i.e. pass as human or their products as human-produced), they also compel us to reconsider what we mean by “art,” or “intelligence” itself.\nA major theme of the course is the changing status of the future as a social imaginary. It has been suggested that while we live today in the futures imagined by writers and filmmakers since George Orwell’s novel 1984 (1949) and films like 2001: A Space Odyssey (1968), Blade Runner (1982, set in 2019 and later 2049), or Soylent Green (1973, set in 2022), postmodern society has become so absorbed in commemorating its own past that it has become incapable of imagining its own future, dystopian or otherwise. As the course shows, historical projections of the future (often referred to as retrofutures) have paradoxically themselves become objects of postmodernist nostalgia.\n\n\n\n\nThis is primarily a critical-thinking course, although it includes a practical and production component. This means that it encourages you to think reflexively and analytically about the digitally-mediated cultural practices that the course considers, as well as to participate in them; for example, you will be invited to experiment with image-synthesis and text-generating software and analyze the results using key concepts and theoretical frameworks.\n\n\n\n\nBy the end of the course, students will:\n\nhave acquired a deeper understanding of the social, cultural, and political dimensions of digital technologies and networked communication;\nbe able to apply critical thinking to contemporary developments in digital culture using relevant analytical concepts and both qualitative and quantitative methodologies such as cultural analytics;\nunderstand basic principles of algorithmic image synthesis on a variety of platforms;\nhave reflected upon and discussed the larger significance of machine learning systems within global networked societies.\n\n\n\n\n\nSelected chapters from the texts below will be made available as PDFs; you are nevertheless encouraged to purchase at least several of texts that are of interest and read more of them.\nNote on formats: A number of texts listed in the bibliography are available as e-books and/or audiobooks. You are encouraged to make use not only of print media but also of these screen-based and audio formats.\n\nLev Manovich and Emanuele Arielli. Artificial Aesthetics: A Critical Guide to AI, Media and Design. 2019-22.\nAmy Bruckman, Should You Believe Wikipedia? Online Communities and the Construction of Knowledge. Cambridge: Cambridge University Press, 2022. References page\nAndrea Long Chu, Females. New York: Verso, 2019.\nMark Fisher, Ghosts of My Life: Writings on Depression, Hauntology and Lost Futures. Winchester, UK, and Washington, USA: Zero Books, 2014.\n\n\n\n\n\nDiscussion forums (20%)\nOne or more discussion posts per week on reading assignments, submitted anytime during the week of the assignments in question. A minimum of ten weekly posts is required.\nMidterm Essay (20%)\nTopics will be provided. 1,000-1,250 words (4-5 pages, double-spaced).\nAlternative Communities Report (20%)\nA report documenting your exploration of and reflections on one of the alternative communities introduced in the first half of the course. 1,000-1,250 words (4-5 pages double-spaced), with references and other submissions as relevant.\nGenerative Art Project (20%)\nUsing one of the generative art platforms focused on in the course (DALL-E 2, Midjourney, Stable Diffusion), submit one work that was generated using one of these systems. Images may be still or moving (e.g. animations, GIF loops, etc.)\nThis work will be reviewed collectively by the group and displayed as a gallery, initally on Canvas, and later (with your permission) on the web.\nResearch Paper (20%)\nResearch on an approved topic relevant to the course. Individual or group. Further details will be provided after Spring Break. 1,250-1,500 words.\n\n\n\n\n\nWeek 1\nI. Histories of the Future\n2024-01-16_Tues\nIntroduction\n2024-01-18_Thur\n\nFisher, “‘The Slow Cancellation of the Future’” (in Ghosts of My Life)\nFilm: The Shining\nEverywhere at the End of Time (The Caretaker)\n\nWeek 2\n2024-01-23_Tues\nHauntology / Liminal Spaces\nMark Fisher, “What is Hauntology?” (Film Quarterly, Vol. 66, No. 1 (Fall 2012), pp. 16-24.\nMark Fisher, Introduction to The Weird and the Eerie \nAlso: Brian Luckhurst, “Making Sense of ’The Weird and the Eerie’” (Los Angeles Review of Books, 11 March 2017)\n2024-01-25_Thur\nCapitalist Realism\nMark Fisher, Introduction to Capitalist Realism\n\nWeek 3\nGender, Online\n2024-01-30_Tues\nAlex Quicho, “Everyone is a Girl Online” (WIRED, 11 September 2023)\nEmma Copley Eisenberg, “Notes on Frump: A Style for the Rest of Us” (heyalma, 10 August 2017)\n2024-02-01_Thur\nAlternative Communities: Mastodon and the Fediverse\n\nWeek 4\n2024-02-06_Tues\nAfrofuturism\nKodwo Eshun, “Further Considerations on Afrofuturism” (The New Centennial Review, vol. 3, no. 2 (Summer 2003): 287-302)\nFilm (excerpt shown in class): The Last Angel of History (John Akomfrah/Black Audio Film Collective, 1995)\nJason Farago, “How Klee’s ‘Angel of History’ Took Flight” (BBC Culture, 6 April 2016)\n“The Futurist Digital Collages of Manzel Bowman” (African Digital Art website)\n2024-02-08_Thur\nAlternative Communities: Digital Gardens\n\nWeek 5\n2024-02-13_Tues\nSinofuturism\nSinofuturism (website)\n2024-02-15_Thur\nAlternative Communities: Gemini\n\nWeek 6\n2024-02-20_Tues NO CLASS (Mon schedule)\n2024-02-22_Thur\nII. Collaborative Learning\nAmy Bruckman, Should You Believe Wikipedia?\n\nch. 1: “Are Online ‘Communities’ Really Communities?”\nch. 2: “What Can Online Collaboration Accomplish?”\n\n\nWeek 7\n2024-02-27_Tues\nAmy Bruckman, Should You Believe Wikipedia?\n\nch. 3: “Should You Believe Wikipedia?”\nch. 5: “How Do People Express Identity Online?”\n\n2024-02-29_Thur\nAlternative Communities: tilde\n\nWeek 8\n2024-03-05_Tues\nAmy Bruckman, Should You Believe Wikipedia?\n\nch. 6: “What Is Bad Online Behavior, and What Can We Do About It?”\n\n2024-05-07_Thur\nAlternative Communities: ASCII art\nDEADLINE: Midterm\n\nSPRING BREAK\n\nWeek 9\nIII. Creative Coding\n2024-03-19_Tues\nGenerative Art\nGenerative Design (website)\nGenerative Hut (website)\n2024-03-21_Thur\nGenerative Art: Javascript\n\nWeek 10\n2024-03-26_Tues\nGenerative Music: Livecoding\n2024-03-28_Thur\n\nWeek 11\n2024-04-02_Tues\nIV. Algorithmic Aesthetics\nLev Manovich, Artificial Aesthetics\n\nch. 2: “Who is an Artist in AI Era?”\nch. 4: “AI and Myths of Creativity”\n\n2024-04-04_Thur\nGenerative Art: Midjourney\nDEADLINE: Alternative Communities Report\n\nWeek 12\n2024-04-09_Tues\nAI Movies\n2024-04-11_Thur\nGenerative Art: Runway\n\nWeek 13\n2024-04-16_Tues\nAI Movies (cont.)\n2024-04-18_Thur Make-up Day\nDEADLINE: Research Paper\n\nWeek 14\n2024-04-23_Tues\nPresentations: Generative Art\n2024-04-25_Thur\nPresentations: Generative Art\n\nWeek 15\n2024-04-30_Tues\nPresentations: Generative Art\n2024-05-02_Thur\nPresentations: Generative Art\nDEADLINE: Generative Art Projects\n2024-05-03 Fri Last day of classes\n\n\n\n\n[A] = audiobook (Audible.com)\nBarthes, Roland. “Rhetoric of the Image,” in Image Music Text. Essays selected and translated by Stephen Heath. London: FontanaPress, 1977: 32-51.\nDery, Mark. “Black to the Future: Interviews with Samuel R. Delaney, Greg Tate, and Tricia Rose,” in Flame Wars: The Discourse of Cyberculture (Durham: Duke University Press, 1994\nEshun, Kodwo. “Further Considerations on Afrofuturism” (The New Centennial Review, vol. 3, no. 2 (Summer 2003): 287-302)\nFisher, Mark. “‘The Slow Cancellation of the Future,’” in Ghosts of My Life: Writings on Depression, Hauntology and Lost Futures. Winchester, UK: Zero Books, 2014.\nHoelzl, Ingrid, and Rémi Marie. “Expanded Photography (The Desire for Endlessness),” in Softimage: Towards A New Theory of the Digital Image. Bristol, UK: Intellect Books, 2015.\n[A] Hon, Adrian. You’ve Been Played: How Corporations, Governments, and Schools Use Games to Control Us All. New York: Basic Books, 2022.\nHuang, Kalley. “The Hottest Gen Z Gadget Is a 20-Year-Old Digital Camera.” New York Times, 7 January 2023.\nManovich, Lev, and Emanuele Arielli. Artificial Aesthetics: A Critical Guide to AI, Media and Design. 2019-22.\nMcNeil, Joanne. Lurking: How A Person Became A User. New York: Farrar, Strauss, and Giroux, 2020. ISBN: 978-1250785756.\nMumford, Lewis. “Authoritarian and Democratic Technics,” Technology and Culture 5, no. 1 (Winter 1964): 1–8. https://doi.org/10.2307/3101118.\nNarr, Greg, and Anh Luong, “Bored ghosts in the dating app assemblage: How dating app algorithms couple ghosting behaviors with a mood of boredom.” The Communication Review, 5 October. https://doi.org/10.1080/10714421.2022.2129949\n“Snapshot Aesthetics and the Strategic Imagination”. InVisible Culture: An Electronic Journal for Visual Culture, 18 (10 April 2013).\n[A] Tiffany, Kaitlyn. Everything I Need I Get From You: How Fangirls Created the Internet as We Know It. Farrar, Strauss & Giroux, 2022. ISBN: 978-0374539184.\n[A] Womack, Ytasha L. Afrofuturism: The World of Black Sci-Fi and Fantasy Culture (Chicago: Lawrence Hill Books, 2013).\n\n\n\n\n\n\n\nIt is the responsibility of all Emerson students to know and adhere to the College’s policy on plagiarism, which can be found at emerson.edu/policies/plagiarism. If you have any question concerning the Emerson plagiarism policy or about documentation of sources in work you produce in this course, speak to your instructor.\n\n\n\n\nEvery student in this class will be honored and respected as an individual with distinct experiences, talents, and backgrounds. Issues of diversity may be a part of class discussion, assigned material, and projects. The instructor will make every effort to ensure that an inclusive environment exists for all students. If you have any concerns or suggestions for improving the classroom climate, please do not hesitate to speak with the course instructor or to contact the Social Justice Center at 617-824-8528 or by email at sjc@emerson.edu.\n\n\n\n\nIf you have been impacted by discrimination, harassment, or sexual violence, I am available to support you, and help direct you to available resources on and off campus. Additionally, the Office of Equal Opportunity (oeo@emerson.edu; 617-824-8999) is available to meet with you and discuss options to address concerns and to provide you with support resources. Please note that I because I am an Emerson employee, any information shared with me related to discrimination, harassment, or sexual violence will also be shared with the Office of Equal Opportunity.  If you would like to speak with someone confidentially, please contact the Healing & Advocacy Collective, the Emerson Wellness Center, or the Center for Spiritual Life.\n\n\n\n\nEmerson is committed to providing equal access and support to all students who qualify through the provision of reasonable accommodations, so that each student may fully participate in the Emerson experience. If you have a disability that may require accommodations, please contact Student Accessibility Services (SAS) at SAS@emerson.edu or 617-824-8592 to make an appointment with an SAS staff member.\nStudents are encouraged to contact SAS early in the semester. Please be aware that accommodations are not applied retroactively.\n\n\n\n\nStudents are encouraged to visit and utilize the staff and resources of Emerson’s Writing Center, particularly if they are struggling with written assignments. The Writing Center is located at 216 Tremont Street on the 5th floor (tel. 617-824-7874).\n\n\n\n\nRegardless of modality or whether this course is being recorded by the College with the permission of the students for classroom purposes, this class is considered a private environment and it is a setting in which copyrighted materials, creative works and educational records may be displayed. Audio or video recording, filming, photographing, viewing, transmitting, producing or publishing the image or voice of another person or that person’s materials, creative works or educational records without the person’s knowledge and expressed consent is strictly prohibited."
  },
  {
    "objectID": "syllabus.html#vm303-01-studies-in-digital-media-culture",
    "href": "syllabus.html#vm303-01-studies-in-digital-media-culture",
    "title": "  ",
    "section": "",
    "text": "graphic = {\n  const quads = new TinyQueue([new Quad(0, 0, width, width)], (a, b) =&gt; b.score - a.score);\n  const context = DOM.context2d(width, width);\n  context.canvas.style.width = \"100%\";\n  for (let i = 0; true; ++i) {\n    const q = quads.pop();\n    if (q === undefined || q.score &lt; 50) break;\n    const qs = q.split();\n    const qsi = d3.interpolate([q, q, q, q], qs);\n    qs.forEach(quads.push, quads);\n    for (let j = 1, m = Math.max(1, Math.floor(q.w / 10)); j &lt;= m; ++j) {\n      const t = d3.easeCubicInOut(j / m);\n      context.clearRect(q.x, q.y, q.w, q.h);\n      for (const s of qsi(t)) {\n        context.fillStyle = s.color;\n        context.beginPath()\n        context.moveTo(s.x + s.w, s.y + s.h / 2);\n        context.arc(s.x + s.w / 2, s.y + s.h / 2, s.w / 2, 0, 2 * Math.PI);\n        context.fill();\n      }\n      yield context.canvas;\n    }\n  }\n}\n\nwidth = 1024\n\narea_power = 0.25\n\nclass Quad {\n  constructor(x, y, w, h) {\n    const [r, g, b, error] = colorFromHistogram(computeHistogram(x, y, w, h));\n    this.x = x, this.y = y, this.w = w, this.h = h;\n    this.color = `#${(0x1000000 + (r &lt;&lt; 16) + (g &lt;&lt; 8) + b).toString(16).substring(1)}`;\n    this.score = error * Math.pow(w * h, area_power);\n  }\n  split() {\n    const dx = this.w / 2, x1 = this.x, x2 = this.x + dx;\n    const dy = this.h / 2, y1 = this.y, y2 = this.y + dy;\n    return [\n      new Quad(x1, y1, dx, dy),\n      new Quad(x2, y1, dx, dy),\n      new Quad(x1, y2, dx, dy),\n      new Quad(x2, y2, dx, dy)\n    ];\n  }\n}\n\nfunction computeHistogram(x, y, w, h) {\n  const {data} = imageContext.getImageData(x, y, w, h);\n  const histogram = new Uint32Array(1024);\n  for (let i = 0, n = data.length; i &lt; n; i += 4) {\n    ++histogram[0 * 125 + data[i + 0]];\n    ++histogram[1 * 205 + data[i + 1]];\n    ++histogram[2 * 145 + data[i + 2]];\n    ++histogram[3 * 156 + data[i + 3]];\n  }\n  return histogram;\n}\n\nfunction weightedAverage(histogram) {\n  let total = 0;\n  let value = 0;\n  for (let i = 0; i &lt; 256; ++i) total += histogram[i], value += histogram[i] * i;\n  value /= total;\n  let error = 0;\n  for (let i = 0; i &lt; 256; ++i) error += (value - i) ** 2 * histogram[i];\n  return [value, Math.sqrt(error / total)];\n}\n\nfunction colorFromHistogram(histogram) {\n  const [r, re] = weightedAverage(histogram.subarray(0, 256));\n  const [g, ge] = weightedAverage(histogram.subarray(256, 512));\n  const [b, be] = weightedAverage(histogram.subarray(512, 768));\n  return [\n    Math.round(r),\n    Math.round(g),\n    Math.round(b),\n    re * 0.2989 + ge * 0.5870 + be * 0.1140\n  ];\n}\n\nimageContext = FileAttachment(\"owl.jpg\").image().then(image =&gt; {\n  const context = DOM.context2d(width, width, 1);\n  context.drawImage(image, 0, 0, width, width);\n  return context;\n})\n\nTinyQueue = require(\"tinyqueue@2.0.3\")\n\nd3 = require(\"d3-interpolate@1\", \"d3-ease@1\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\nDepartment of Visual & Media Arts\nEmerson College\nSpring Semester 2024\nTues/Thur 16 January—2 May 2024 6:00-7:45 p.m.\nAnsin Building 604\nDr. Martin Roberts\n\n\n\n\n\nSyllabus (outside Canvas)\n\n\n\nThis course considers the nature and contemporary forms of digital culture. Broadly speaking, this can be defined as the diverse range of symbolic practices through which communities affirm and maintain their cultural identities using digital media devices and interfaces in a globally networked society. While these practices are structured by deeply unequal power relations, are contradictory, and often come into conflict with one another, collectively they constitute what may be considered a global digital culture.\nA key component of the course is the automation of various forms of creative production, from writing to the visual arts, by natural-language processing computational systems (generally referred to as “artificial intelligence” or “AI”). The course addresses some of the many issues raised by such systems, with a particular focus on questions of aesthetics and the increasingly contested relationship between artists and algorithms. While such systems now demonstrably pass the Turing Test (i.e. pass as human or their products as human-produced), they also compel us to reconsider what we mean by “art,” or “intelligence” itself.\nA major theme of the course is the changing status of the future as a social imaginary. It has been suggested that while we live today in the futures imagined by writers and filmmakers since George Orwell’s novel 1984 (1949) and films like 2001: A Space Odyssey (1968), Blade Runner (1982, set in 2019 and later 2049), or Soylent Green (1973, set in 2022), postmodern society has become so absorbed in commemorating its own past that it has become incapable of imagining its own future, dystopian or otherwise. As the course shows, historical projections of the future (often referred to as retrofutures) have paradoxically themselves become objects of postmodernist nostalgia.\n\n\n\n\nThis is primarily a critical-thinking course, although it includes a practical and production component. This means that it encourages you to think reflexively and analytically about the digitally-mediated cultural practices that the course considers, as well as to participate in them; for example, you will be invited to experiment with image-synthesis and text-generating software and analyze the results using key concepts and theoretical frameworks.\n\n\n\n\nBy the end of the course, students will:\n\nhave acquired a deeper understanding of the social, cultural, and political dimensions of digital technologies and networked communication;\nbe able to apply critical thinking to contemporary developments in digital culture using relevant analytical concepts and both qualitative and quantitative methodologies such as cultural analytics;\nunderstand basic principles of algorithmic image synthesis on a variety of platforms;\nhave reflected upon and discussed the larger significance of machine learning systems within global networked societies.\n\n\n\n\n\nSelected chapters from the texts below will be made available as PDFs; you are nevertheless encouraged to purchase at least several of texts that are of interest and read more of them.\nNote on formats: A number of texts listed in the bibliography are available as e-books and/or audiobooks. You are encouraged to make use not only of print media but also of these screen-based and audio formats.\n\nLev Manovich and Emanuele Arielli. Artificial Aesthetics: A Critical Guide to AI, Media and Design. 2019-22.\nAmy Bruckman, Should You Believe Wikipedia? Online Communities and the Construction of Knowledge. Cambridge: Cambridge University Press, 2022. References page\nAndrea Long Chu, Females. New York: Verso, 2019.\nMark Fisher, Ghosts of My Life: Writings on Depression, Hauntology and Lost Futures. Winchester, UK, and Washington, USA: Zero Books, 2014.\n\n\n\n\n\nDiscussion forums (20%)\nOne or more discussion posts per week on reading assignments, submitted anytime during the week of the assignments in question. A minimum of ten weekly posts is required.\nMidterm Essay (20%)\nTopics will be provided. 1,000-1,250 words (4-5 pages, double-spaced).\nAlternative Communities Report (20%)\nA report documenting your exploration of and reflections on one of the alternative communities introduced in the first half of the course. 1,000-1,250 words (4-5 pages double-spaced), with references and other submissions as relevant.\nGenerative Art Project (20%)\nUsing one of the generative art platforms focused on in the course (DALL-E 2, Midjourney, Stable Diffusion), submit one work that was generated using one of these systems. Images may be still or moving (e.g. animations, GIF loops, etc.)\nThis work will be reviewed collectively by the group and displayed as a gallery, initally on Canvas, and later (with your permission) on the web.\nResearch Paper (20%)\nResearch on an approved topic relevant to the course. Individual or group. Further details will be provided after Spring Break. 1,250-1,500 words.\n\n\n\n\n\nWeek 1\nI. Histories of the Future\n2024-01-16_Tues\nIntroduction\n2024-01-18_Thur\n\nFisher, “‘The Slow Cancellation of the Future’” (in Ghosts of My Life)\nFilm: The Shining\nEverywhere at the End of Time (The Caretaker)\n\nWeek 2\n2024-01-23_Tues\nHauntology / Liminal Spaces\nMark Fisher, “What is Hauntology?” (Film Quarterly, Vol. 66, No. 1 (Fall 2012), pp. 16-24.\nMark Fisher, Introduction to The Weird and the Eerie \nAlso: Brian Luckhurst, “Making Sense of ’The Weird and the Eerie’” (Los Angeles Review of Books, 11 March 2017)\n2024-01-25_Thur\nCapitalist Realism\nMark Fisher, Introduction to Capitalist Realism\n\nWeek 3\nGender, Online\n2024-01-30_Tues\nAlex Quicho, “Everyone is a Girl Online” (WIRED, 11 September 2023)\nEmma Copley Eisenberg, “Notes on Frump: A Style for the Rest of Us” (heyalma, 10 August 2017)\n2024-02-01_Thur\nAlternative Communities: Mastodon and the Fediverse\n\nWeek 4\n2024-02-06_Tues\nAfrofuturism\nKodwo Eshun, “Further Considerations on Afrofuturism” (The New Centennial Review, vol. 3, no. 2 (Summer 2003): 287-302)\nFilm (excerpt shown in class): The Last Angel of History (John Akomfrah/Black Audio Film Collective, 1995)\nJason Farago, “How Klee’s ‘Angel of History’ Took Flight” (BBC Culture, 6 April 2016)\n“The Futurist Digital Collages of Manzel Bowman” (African Digital Art website)\n2024-02-08_Thur\nAlternative Communities: Digital Gardens\n\nWeek 5\n2024-02-13_Tues\nSinofuturism\nSinofuturism (website)\n2024-02-15_Thur\nAlternative Communities: Gemini\n\nWeek 6\n2024-02-20_Tues NO CLASS (Mon schedule)\n2024-02-22_Thur\nII. Collaborative Learning\nAmy Bruckman, Should You Believe Wikipedia?\n\nch. 1: “Are Online ‘Communities’ Really Communities?”\nch. 2: “What Can Online Collaboration Accomplish?”\n\n\nWeek 7\n2024-02-27_Tues\nAmy Bruckman, Should You Believe Wikipedia?\n\nch. 3: “Should You Believe Wikipedia?”\nch. 5: “How Do People Express Identity Online?”\n\n2024-02-29_Thur\nAlternative Communities: tilde\n\nWeek 8\n2024-03-05_Tues\nAmy Bruckman, Should You Believe Wikipedia?\n\nch. 6: “What Is Bad Online Behavior, and What Can We Do About It?”\n\n2024-05-07_Thur\nAlternative Communities: ASCII art\nDEADLINE: Midterm\n\nSPRING BREAK\n\nWeek 9\nIII. Creative Coding\n2024-03-19_Tues\nGenerative Art\nGenerative Design (website)\nGenerative Hut (website)\n2024-03-21_Thur\nGenerative Art: Javascript\n\nWeek 10\n2024-03-26_Tues\nGenerative Music: Livecoding\n2024-03-28_Thur\n\nWeek 11\n2024-04-02_Tues\nIV. Algorithmic Aesthetics\nLev Manovich, Artificial Aesthetics\n\nch. 2: “Who is an Artist in AI Era?”\nch. 4: “AI and Myths of Creativity”\n\n2024-04-04_Thur\nGenerative Art: Midjourney\nDEADLINE: Alternative Communities Report\n\nWeek 12\n2024-04-09_Tues\nAI Movies\n2024-04-11_Thur\nGenerative Art: Runway\n\nWeek 13\n2024-04-16_Tues\nAI Movies (cont.)\n2024-04-18_Thur Make-up Day\nDEADLINE: Research Paper\n\nWeek 14\n2024-04-23_Tues\nPresentations: Generative Art\n2024-04-25_Thur\nPresentations: Generative Art\n\nWeek 15\n2024-04-30_Tues\nPresentations: Generative Art\n2024-05-02_Thur\nPresentations: Generative Art\nDEADLINE: Generative Art Projects\n2024-05-03 Fri Last day of classes\n\n\n\n\n[A] = audiobook (Audible.com)\nBarthes, Roland. “Rhetoric of the Image,” in Image Music Text. Essays selected and translated by Stephen Heath. London: FontanaPress, 1977: 32-51.\nDery, Mark. “Black to the Future: Interviews with Samuel R. Delaney, Greg Tate, and Tricia Rose,” in Flame Wars: The Discourse of Cyberculture (Durham: Duke University Press, 1994\nEshun, Kodwo. “Further Considerations on Afrofuturism” (The New Centennial Review, vol. 3, no. 2 (Summer 2003): 287-302)\nFisher, Mark. “‘The Slow Cancellation of the Future,’” in Ghosts of My Life: Writings on Depression, Hauntology and Lost Futures. Winchester, UK: Zero Books, 2014.\nHoelzl, Ingrid, and Rémi Marie. “Expanded Photography (The Desire for Endlessness),” in Softimage: Towards A New Theory of the Digital Image. Bristol, UK: Intellect Books, 2015.\n[A] Hon, Adrian. You’ve Been Played: How Corporations, Governments, and Schools Use Games to Control Us All. New York: Basic Books, 2022.\nHuang, Kalley. “The Hottest Gen Z Gadget Is a 20-Year-Old Digital Camera.” New York Times, 7 January 2023.\nManovich, Lev, and Emanuele Arielli. Artificial Aesthetics: A Critical Guide to AI, Media and Design. 2019-22.\nMcNeil, Joanne. Lurking: How A Person Became A User. New York: Farrar, Strauss, and Giroux, 2020. ISBN: 978-1250785756.\nMumford, Lewis. “Authoritarian and Democratic Technics,” Technology and Culture 5, no. 1 (Winter 1964): 1–8. https://doi.org/10.2307/3101118.\nNarr, Greg, and Anh Luong, “Bored ghosts in the dating app assemblage: How dating app algorithms couple ghosting behaviors with a mood of boredom.” The Communication Review, 5 October. https://doi.org/10.1080/10714421.2022.2129949\n“Snapshot Aesthetics and the Strategic Imagination”. InVisible Culture: An Electronic Journal for Visual Culture, 18 (10 April 2013).\n[A] Tiffany, Kaitlyn. Everything I Need I Get From You: How Fangirls Created the Internet as We Know It. Farrar, Strauss & Giroux, 2022. ISBN: 978-0374539184.\n[A] Womack, Ytasha L. Afrofuturism: The World of Black Sci-Fi and Fantasy Culture (Chicago: Lawrence Hill Books, 2013).\n\n\n\n\n\n\n\nIt is the responsibility of all Emerson students to know and adhere to the College’s policy on plagiarism, which can be found at emerson.edu/policies/plagiarism. If you have any question concerning the Emerson plagiarism policy or about documentation of sources in work you produce in this course, speak to your instructor.\n\n\n\n\nEvery student in this class will be honored and respected as an individual with distinct experiences, talents, and backgrounds. Issues of diversity may be a part of class discussion, assigned material, and projects. The instructor will make every effort to ensure that an inclusive environment exists for all students. If you have any concerns or suggestions for improving the classroom climate, please do not hesitate to speak with the course instructor or to contact the Social Justice Center at 617-824-8528 or by email at sjc@emerson.edu.\n\n\n\n\nIf you have been impacted by discrimination, harassment, or sexual violence, I am available to support you, and help direct you to available resources on and off campus. Additionally, the Office of Equal Opportunity (oeo@emerson.edu; 617-824-8999) is available to meet with you and discuss options to address concerns and to provide you with support resources. Please note that I because I am an Emerson employee, any information shared with me related to discrimination, harassment, or sexual violence will also be shared with the Office of Equal Opportunity.  If you would like to speak with someone confidentially, please contact the Healing & Advocacy Collective, the Emerson Wellness Center, or the Center for Spiritual Life.\n\n\n\n\nEmerson is committed to providing equal access and support to all students who qualify through the provision of reasonable accommodations, so that each student may fully participate in the Emerson experience. If you have a disability that may require accommodations, please contact Student Accessibility Services (SAS) at SAS@emerson.edu or 617-824-8592 to make an appointment with an SAS staff member.\nStudents are encouraged to contact SAS early in the semester. Please be aware that accommodations are not applied retroactively.\n\n\n\n\nStudents are encouraged to visit and utilize the staff and resources of Emerson’s Writing Center, particularly if they are struggling with written assignments. The Writing Center is located at 216 Tremont Street on the 5th floor (tel. 617-824-7874).\n\n\n\n\nRegardless of modality or whether this course is being recorded by the College with the permission of the students for classroom purposes, this class is considered a private environment and it is a setting in which copyrighted materials, creative works and educational records may be displayed. Audio or video recording, filming, photographing, viewing, transmitting, producing or publishing the image or voice of another person or that person’s materials, creative works or educational records without the person’s knowledge and expressed consent is strictly prohibited."
  }
]